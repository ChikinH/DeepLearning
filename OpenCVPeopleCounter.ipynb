{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "OpenCVPeopleCounter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSrXFTa7llSzUtSZIc6OLv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChikinH/DeepLearning/blob/main/OpenCVPeopleCounter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iKkSddRpMoZ"
      },
      "source": [
        "Data mining project done by Cousin Antoine during master's degree.\n",
        "People detection then tracking, to count them in many ways."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgJT5b1hpJEa",
        "outputId": "c2e7241c-a1d6-42bf-81e7-72aeca061783"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSMKmfxqsd3P"
      },
      "source": [
        "Creation of trackable object class.\n",
        "Three fields:\n",
        "- object id\n",
        "- counted boolean\n",
        "- list of centroids (center of bounding box)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo5zL7D6pcDv"
      },
      "source": [
        "class TrackableObject():\n",
        "  def __init__(self, id, centroid):\n",
        "    self.id = id\n",
        "    self.counted = False\n",
        "    self.centroids = [centroid]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgAuLNzptV2C"
      },
      "source": [
        "Now we need a centroid tracker.  \n",
        "It need to know how many frames bedore we consider that an object disappeared.  \n",
        "It also need to store object present on video stream, and those that disappeared less than frameBeforeDisappered frames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6t4kQxBtV-N"
      },
      "source": [
        "from scipy.spatial import distance as dist\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "class CentroidTracker():\n",
        "  def __init__(self, frameBeforeDisappeared=100):\n",
        "    self.nextID=0\n",
        "    self.objects = OrderedDict()\n",
        "    self.disappeared = OrderedDict()\n",
        "    self.frameBeforeDisappeared = frameBeforeDisappeared\n",
        "  \n",
        "  def register(self, centroid):\n",
        "    self.objects[self.nextID] = centroid\n",
        "    self.disappeared[self.nextID] = 0\n",
        "    self.nextID += 1\n",
        "  \n",
        "  def deregister(self, id):\n",
        "    del self.objects[id]\n",
        "    del self.disappeared[id]\n",
        "\n",
        "  def update(self, rects):\n",
        "  # rects are bounding box given by an object detector\n",
        "    if len(rects)==0:\n",
        "      # no more object on image\n",
        "      for id in list(self.disappeared.keys()):\n",
        "        self.disappeared[id] += 1\n",
        "        if self.disappeared[id] > self.frameBeforeDisappeared:\n",
        "          self.deregister(id)\n",
        "      return self.objects\n",
        "    # compute centroids from rectangles\n",
        "    inputCentroids = np.zeros((len(rects),2),dtype=\"int\")\n",
        "    for (i,(startX,startY,endX,endY)) in enumerate(rects):\n",
        "      cX = int((startX+endX)/2)\n",
        "      cY = int((startY+endY)/2)\n",
        "      inputCentroids[i] =(cX,cY)\n",
        "\n",
        "    # if no object is currently tracked, register all centroids\n",
        "    if len(self.objects) == 0:\n",
        "      for i in range(0, len(inputCentroids)):\n",
        "        self.register(inputCentroids[i])\n",
        "\n",
        "    # otherwise we match existing centroid, or register new ones\n",
        "    else:\n",
        "      objectIDs = list(self.objects.keys())\n",
        "      objectCentroids = list(self.objects.values())\n",
        "\n",
        "      # compute euclidian distance between pair of existing centroid and input ones, then sorting the distances\n",
        "      D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
        "      rows = D.min(axis=1).argsort()\n",
        "      cols = D.argmin(axis=1)[rows]\n",
        "\n",
        "      # use the distance to see if we can match objects\n",
        "      usedRows = set()\n",
        "      usedCols = set()\n",
        "\n",
        "      for (row,col) in zip(rows,cols):\n",
        "        if row in usedRows or col in usedCols:\n",
        "          continue\n",
        "        \n",
        "        # update existing centroid\n",
        "        objectID = objectIDs[row]\n",
        "        self.objects[objectID] = inputCentroids[col]\n",
        "        self.disappeared[objectID] = 0\n",
        "\n",
        "        usedRows.add(row)\n",
        "        usedCols.add(col)\n",
        "      \n",
        "      # compute rows and col not used\n",
        "      unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
        "      unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
        "\n",
        "      # if there is more centroid existing than inputed ones, we check the ones missing\n",
        "      if D.shape[0] >= D.shape[1]:\n",
        "        for row in unusedRows:\n",
        "          objectID = objectIDs[row]\n",
        "          self.disappeared[objectID] += 1\n",
        "          if self.disappeared[objectID] > self.frameBeforeDisappeared:\n",
        "            self.deregister(objectID)\n",
        "      # else we need to register new centroid\n",
        "      else:\n",
        "        for col in unusedCols:\n",
        "          self.register(inputCentroids[col])\n",
        "    return self.objects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1kLz8Gru_eC"
      },
      "source": [
        "Below, we implement our people counter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZwgzjsTu_kV"
      },
      "source": [
        "import argparse\n",
        "import cv2\n",
        "import dlib\n",
        "import imutils\n",
        "import time\n",
        "import pandas as pd\n",
        "from imutils.video import VideoStream\n",
        "from imutils.video import FPS\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bVRrrl7cinC"
      },
      "source": [
        "We load a pre-trained model able to detect few classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXgYHDWDXyLg"
      },
      "source": [
        "# code for mobilenet ssd (unused)\n",
        "\n",
        "#CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
        "#\t\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "#\t\"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
        "#\t\"sofa\", \"train\", \"tvmonitor\"]\n",
        "\n",
        "# net = cv2.dnn.readNetFromCaffe(\"/content/drive/MyDrive/Colab Notebooks/DataMining/mobilenet_ssd/MobileNetSSD_deploy.prototxt.txt\", \"/content/drive/MyDrive/Colab Notebooks/DataMining/mobilenet_ssd/MobileNetSSD_deploy.caffemodel\")\n",
        "\n",
        "# code for yolo\n",
        "\n",
        "labelsPath = \"/content/drive/MyDrive/Colab Notebooks/DataMining/yolo/coco.names\"\n",
        "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
        "\n",
        "np.random.seed(42)\n",
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),\n",
        "\tdtype=\"uint8\")\n",
        "\n",
        "configPath = \"/content/drive/MyDrive/Colab Notebooks/DataMining/yolo/yolov3.cfg\"\n",
        "weightsPath = \"/content/drive/MyDrive/Colab Notebooks/DataMining/yolo/yolov3.weights\"\n",
        "\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "\n",
        "ln = net.getLayerNames()\n",
        "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPr65CfafCmd"
      },
      "source": [
        "def my_tracker(input, output, target=\"person\", display=False):\n",
        "  dataframe = pd.DataFrame(columns=[\"id\",\"frame\", \"direction\"])\n",
        "\n",
        "  vs = cv2.VideoCapture(input)\n",
        "\n",
        "  frames = int(vs.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  writer = None\n",
        "\n",
        "  W = None\n",
        "  H = None\n",
        "\n",
        "  ct = CentroidTracker(frameBeforeDisappeared=50)\n",
        "  trackers = []\n",
        "  trackableObjects = {}\n",
        "\n",
        "  totalFrames = 0\n",
        "  totalDown = 0\n",
        "  totalUp = 0\n",
        "\n",
        "  fps = FPS().start()\n",
        "\n",
        "  while True:\n",
        "    frame = vs.read()\n",
        "    frame = frame[1]\n",
        "    if totalFrames == frames:\n",
        "      break\n",
        "\n",
        "    frame = imutils.resize(frame, width=500)\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    if W is None or H is None:\n",
        "      (H,W) = frame.shape[:2]\n",
        "    if writer is None:\n",
        "      fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "      writer = cv2.VideoWriter(output,fourcc, 30, (W,H), True)\n",
        "\n",
        "    status = \"Waiting\"\n",
        "    rects = []\n",
        "\n",
        "    if totalFrames % 30 == 0:\n",
        "      status = \"Detecting\"\n",
        "      trackers = []\n",
        "\n",
        "      blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
        "      net.setInput(blob)\n",
        "      start = time.time()\n",
        "      layerOutput = net.forward(ln)\n",
        "      end = time.time()\n",
        "\n",
        "      for output in layerOutput:\n",
        "        for detection in output:\n",
        "          scores = detection[5:]\n",
        "          classID = np.argmax(scores)\n",
        "          confidence = scores[classID]\n",
        "\n",
        "          if LABELS[classID] != target:\n",
        "            continue\n",
        "\n",
        "          if confidence > 0.8:\n",
        "            box = detection[0:4] * np.array([W, H, W, H])\n",
        "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "            startX = int(centerX - (width / 2))\n",
        "            startY = int(centerY - (height / 2))\n",
        "            endX = int(centerX + (width / 2))\n",
        "            endY = int(centerY + (height / 2))\n",
        "\n",
        "            tracker = dlib.correlation_tracker()\n",
        "            rect = dlib.rectangle(startX, startY, endX, endY)\n",
        "            rects.append((startX, startY, endX, endY))\n",
        "            tracker.start_track(rgb, rect)\n",
        "\n",
        "            trackers.append(tracker)\n",
        "\n",
        "    else:\n",
        "      for tracker in trackers:\n",
        "        status = \"Tracking\"\n",
        "        tracker.update(rgb)\n",
        "        pos = tracker.get_position()\n",
        "        startX = int(pos.left())\n",
        "        startY = int(pos.top())\n",
        "        endX = int(pos.right())\n",
        "        endY = int(pos.bottom())\n",
        "        rects.append((startX, startY, endX, endY))\n",
        "      \n",
        "    cv2.line(frame, (0,H//2), (W,H//2),(0,255,255),2)\n",
        "    objects = ct.update(rects)\n",
        "    for (objectID, centroid) in objects.items():\n",
        "      to = trackableObjects.get(objectID,None)\n",
        "\n",
        "      if to is None:\n",
        "        to = TrackableObject(objectID, centroid)\n",
        "\n",
        "      else:\n",
        "        y=[c[1] for c in to.centroids]\n",
        "        direction = centroid[1] - np.mean(y)\n",
        "        to.centroids.append(centroid)\n",
        "\n",
        "        if not to.counted:\n",
        "          if direction < 0 and centroid[1] < H//2:\n",
        "            totalUp += 1\n",
        "            to.counted = True\n",
        "            dataframe = dataframe.append(pd.DataFrame([[objectID, totalFrames, 0]], columns=[\"id\",\"frame\", \"direction\"]), ignore_index=True)\n",
        "            \n",
        "          elif direction > 0 and centroid[1] > H//2:\n",
        "            totalDown += 1\n",
        "            to.counted = True\n",
        "            dataframe = dataframe.append(pd.DataFrame([[objectID, totalFrames, 1]], columns=[\"id\",\"frame\", \"direction\"]), ignore_index=True)\n",
        "      trackableObjects[objectID] = to\n",
        "          \n",
        "      text = \"ID {}\".format(objectID)\n",
        "      cv2.putText(frame, text, (centroid[0]-10, centroid[1]-10), cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
        "      cv2.circle(frame,(centroid[0],centroid[1]),4,(0,255,0),-1)\n",
        "\n",
        "    info = [(\"Up\",totalUp),(\"Down\",totalDown),(\"Status\",status)]\n",
        "    for (i, (k,v)) in enumerate(info):\n",
        "      text = \"{} : {}\".format(k,v)\n",
        "      cv2.putText(frame, text, (10,H-((i*20)+20)), cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)\n",
        "    writer.write(frame)\n",
        "\n",
        "    if display and totalFrames % 15 == 0:\n",
        "      cv2_imshow(frame)\n",
        "\n",
        "    totalFrames += 1\n",
        "    fps.update()\n",
        "  return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdCAhr_hTKpb"
      },
      "source": [
        "# count on a video, return a dataframe with all the object counted\n",
        "data = my_tracker(\"/content/drive/MyDrive/Colab Notebooks/DataMining/Datas/carhighway.mp4\",\"/content/drive/MyDrive/Colab Notebooks/DataMining/Datas/outcarhighwayvideo.mp4\", target=\"car\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "js1VcA4MGVRg",
        "outputId": "379f4a3c-2f98-440d-ce3d-da7b6f2b6a0f"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>frame</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  id frame direction\n",
              "0  0    56         1\n",
              "1  1    58         1\n",
              "2  4    60         0\n",
              "3  6    61         1\n",
              "4  3    86         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qedBxpQMLzl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "64ad71f2-b159-4251-9458-40ae28dc9021"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>frame</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>25</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>25</td>\n",
              "      <td>281</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  frame  direction\n",
              "count   25     25         25\n",
              "unique  25     24          2\n",
              "top     25    281          1\n",
              "freq     1      2         14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVu2bLhC7Dfq",
        "outputId": "c387ae95-b22a-4568-9639-426da588a714"
      },
      "source": [
        "data = data.query(\"direction == 1\")\n",
        "data.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDd11MqD7_dP"
      },
      "source": [
        "It is possible to count car, person or other classes in LABELS :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2smr6lF8KVA",
        "outputId": "9426576e-2b4e-401e-a57b-40adadbd7a3f"
      },
      "source": [
        "print(LABELS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfU4LchW8wad"
      },
      "source": [
        "The first purpose is to perform statistical analysis, on the attendance of shops for example.  \n",
        "With enough data extraction from a camera, it could be possible to train a linear model to predict how many customer will come on a precise day. Adding data like date, weather, or anything that affect the sells is recommended."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1mARyqb7pCg"
      },
      "source": [
        "Sources : pyimagesearch.com"
      ]
    }
  ]
}